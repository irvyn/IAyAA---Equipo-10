{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Ee9SfRM5UXAa",
        "f4GHJuyHuhYM",
        "CLWCrmnpse89"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irvyn/IAyAA---Equipo-10/blob/main/ActividadArbolesPorEquipos_Equipo10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Maestría en Inteligencia Artificial Aplicada**\n",
        "\n",
        "## **Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "\n",
        "Tecnológico de Monterrey\n",
        "\n",
        "Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "**Actividad de la Semana 5**\n",
        "\n",
        "### **Modelos basados en Árboles**\n"
      ],
      "metadata": {
        "id": "jGyrTCouSScG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Nombres y matrículas de los integrantes del Equipo:**\n",
        "\n",
        "*   Anna Franziska María Heuberger - A01796952\n",
        "*   Fernando Moreira Guerra - A00618568\n",
        "*   Irving Alan García Zapata - A01796793\n",
        "*   Rut Godínez Necoechea - A01796539\n",
        "\n"
      ],
      "metadata": {
        "id": "SxfoKPliSz3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PARTE - 1 - Bosque Aleatorio (Random Forest) - Clasificación**"
      ],
      "metadata": {
        "id": "aJvdRW_asVWr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oLDgzdzq5szg"
      },
      "outputs": [],
      "source": [
        "# Importamos lo necesario para la actividad\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, learning_curve, cross_val_score, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import make_scorer, recall_score, accuracy_score, precision_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "from imblearn.pipeline import Pipeline  # Observa que usamos imblearn.Pipeline en lugar de sklearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "\n",
        "# Semilla para reproducibilidad\n",
        "np.random.seed(17)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para esta actividad vamos a generar datos sintéticos para un problema de\n",
        "# clasificación binario utilizando \"make_classification\" de sklearn.\n",
        "\n",
        "# Recuerda consultar la documentación para mayor información:\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html\n",
        "\n",
        "# Utilizaremos los siguientes calores de los hiperparámetros de make_classification:\n",
        "# - n_samples: número de muestras (10,000)\n",
        "# - n_features: número total de características (20)\n",
        "# - n_informative: número de características informativas (14)\n",
        "# - n_redundant: número de características redundantes (6) .. .incluímos algunas redundantes\n",
        "# - weights: pesos para las clases [0,1]-->[0.9, 0.1] para conseguir el desbalance 90%-10%\n",
        "# - class_sep: separación entre clases (mayor valor --> clases más separables y menos complejo)\n",
        "# - flip_y: fracción de ejemplos cuya clase se cambia aleatoriamente (ruido), para hacerlo más complejo\n",
        "# - random_state: semilla para reproducibilidad\n",
        "\n",
        "X, y = make_classification(\n",
        "    n_samples=10_000,          # 10,000 registros\n",
        "    n_features=20,             # 20 factores en total\n",
        "    n_informative=14,          # 14 factores informativos\n",
        "    n_redundant=6,             # 6 factores redundantes (dependientes)\n",
        "    weights=[0.9, 0.1],        # Desbalance de clases: 90% clase 0, 10% clase 1\n",
        "    class_sep=1.0,             # Separación entre clases\n",
        "    n_classes=2,               # Dos clases\n",
        "    n_clusters_per_class=1,    # Si queremos agregar complejidad adicional > 1\n",
        "    flip_y=0.03,               # Añadir algo de ruido. default 0.01\n",
        "    random_state=17,\n",
        ")"
      ],
      "metadata": {
        "id": "Gv02e0nI5ylj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Por el momento generaremos un conjunto de dato que supondremos ya\n",
        "# están escalados y todos las variables son numéricas, para concentrarnos\n",
        "# en el modelo de Bosque Aleatrorio.\n",
        "\n",
        "# Escalamos las características para que estén en el mismo rango:\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Creamos un DataFrame para su mejor manejo\n",
        "feature_names = [f'feature_{i+1}' for i in range(20)]\n",
        "df = pd.DataFrame(X_scaled, columns=feature_names)\n",
        "df['target'] = y\n",
        "\n",
        "print(f\"Total de registros generados: {len(df)}\")\n",
        "print(f\"Distribución de clases: {df['target'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'}\")\n",
        "print(f\"Cantidad de features: {len(feature_names)}\")"
      ],
      "metadata": {
        "id": "QMhcUInh78C1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5bfa77a-4efc-4182-bc42-2017d48270ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de registros generados: 10000\n",
            "Distribución de clases: target\n",
            "0    88.9%\n",
            "1    11.1%\n",
            "Name: proportion, dtype: object\n",
            "Cantidad de features: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(df).describe().T   # Observamos que todos los factores varían en el mismo\n",
        "                                # rango de aproximadamente -4 y 4."
      ],
      "metadata": {
        "id": "jkmFcmS-7rnP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab3bb1c1-6123-4761-e011-7bf1c6df86a2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              count          mean       std       min       25%       50%  \\\n",
              "feature_1   10000.0  2.314948e-15  1.000050 -4.649097 -0.633377  0.035887   \n",
              "feature_2   10000.0  5.332623e-16  1.000050 -3.797292 -0.667241  0.012047   \n",
              "feature_3   10000.0  2.275868e-15  1.000050 -3.171984 -0.679866  0.006216   \n",
              "feature_4   10000.0  8.643752e-16  1.000050 -3.458223 -0.682357 -0.011411   \n",
              "feature_5   10000.0  2.057732e-15  1.000050 -3.822539 -0.669778 -0.007754   \n",
              "feature_6   10000.0  9.293899e-16  1.000050 -3.907304 -0.680717  0.003414   \n",
              "feature_7   10000.0 -1.179501e-16  1.000050 -3.550818 -0.687698 -0.002940   \n",
              "feature_8   10000.0  1.623945e-15  1.000050 -4.628708 -0.669709  0.003945   \n",
              "feature_9   10000.0 -2.810907e-15  1.000050 -3.921339 -0.676168  0.012378   \n",
              "feature_10  10000.0  1.605471e-15  1.000050 -3.611846 -0.690308 -0.006640   \n",
              "feature_11  10000.0 -8.562040e-17  1.000050 -3.671953 -0.686554 -0.008058   \n",
              "feature_12  10000.0  1.866240e-15  1.000050 -4.305611 -0.666463  0.025819   \n",
              "feature_13  10000.0  9.450218e-17  1.000050 -3.919694 -0.680962 -0.006143   \n",
              "feature_14  10000.0  1.151079e-16  1.000050 -3.818618 -0.664539  0.017676   \n",
              "feature_15  10000.0  3.289813e-15  1.000050 -4.524163 -0.665927  0.004529   \n",
              "feature_16  10000.0 -5.728751e-16  1.000050 -3.241478 -0.684383 -0.018401   \n",
              "feature_17  10000.0 -1.172396e-16  1.000050 -4.710243 -0.629663  0.020866   \n",
              "feature_18  10000.0 -5.616840e-16  1.000050 -3.576276 -0.666026  0.009615   \n",
              "feature_19  10000.0  9.098500e-16  1.000050 -3.771503 -0.676057  0.000224   \n",
              "feature_20  10000.0 -8.810730e-17  1.000050 -3.281709 -0.682515 -0.016295   \n",
              "target      10000.0  1.114000e-01  0.314643  0.000000  0.000000  0.000000   \n",
              "\n",
              "                 75%       max  \n",
              "feature_1   0.677096  3.913299  \n",
              "feature_2   0.671898  3.658035  \n",
              "feature_3   0.671532  4.208274  \n",
              "feature_4   0.677787  3.485939  \n",
              "feature_5   0.668929  3.842924  \n",
              "feature_6   0.669981  3.781757  \n",
              "feature_7   0.665087  3.459775  \n",
              "feature_8   0.669659  4.161228  \n",
              "feature_9   0.676704  3.764050  \n",
              "feature_10  0.672674  4.104303  \n",
              "feature_11  0.683646  3.568987  \n",
              "feature_12  0.675121  3.498677  \n",
              "feature_13  0.661320  3.998092  \n",
              "feature_14  0.669214  3.913242  \n",
              "feature_15  0.670484  4.338710  \n",
              "feature_16  0.652103  4.224542  \n",
              "feature_17  0.674894  3.584727  \n",
              "feature_18  0.662473  3.890533  \n",
              "feature_19  0.663606  3.690522  \n",
              "feature_20  0.660956  4.115485  \n",
              "target      0.000000  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5af2e84-36e3-4bee-a24b-f7d0429d9f17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>feature_1</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>2.314948e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.649097</td>\n",
              "      <td>-0.633377</td>\n",
              "      <td>0.035887</td>\n",
              "      <td>0.677096</td>\n",
              "      <td>3.913299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_2</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>5.332623e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.797292</td>\n",
              "      <td>-0.667241</td>\n",
              "      <td>0.012047</td>\n",
              "      <td>0.671898</td>\n",
              "      <td>3.658035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_3</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>2.275868e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.171984</td>\n",
              "      <td>-0.679866</td>\n",
              "      <td>0.006216</td>\n",
              "      <td>0.671532</td>\n",
              "      <td>4.208274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_4</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>8.643752e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.458223</td>\n",
              "      <td>-0.682357</td>\n",
              "      <td>-0.011411</td>\n",
              "      <td>0.677787</td>\n",
              "      <td>3.485939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_5</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>2.057732e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.822539</td>\n",
              "      <td>-0.669778</td>\n",
              "      <td>-0.007754</td>\n",
              "      <td>0.668929</td>\n",
              "      <td>3.842924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_6</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>9.293899e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.907304</td>\n",
              "      <td>-0.680717</td>\n",
              "      <td>0.003414</td>\n",
              "      <td>0.669981</td>\n",
              "      <td>3.781757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_7</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-1.179501e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.550818</td>\n",
              "      <td>-0.687698</td>\n",
              "      <td>-0.002940</td>\n",
              "      <td>0.665087</td>\n",
              "      <td>3.459775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_8</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.623945e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.628708</td>\n",
              "      <td>-0.669709</td>\n",
              "      <td>0.003945</td>\n",
              "      <td>0.669659</td>\n",
              "      <td>4.161228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_9</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-2.810907e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.921339</td>\n",
              "      <td>-0.676168</td>\n",
              "      <td>0.012378</td>\n",
              "      <td>0.676704</td>\n",
              "      <td>3.764050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_10</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.605471e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.611846</td>\n",
              "      <td>-0.690308</td>\n",
              "      <td>-0.006640</td>\n",
              "      <td>0.672674</td>\n",
              "      <td>4.104303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_11</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-8.562040e-17</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.671953</td>\n",
              "      <td>-0.686554</td>\n",
              "      <td>-0.008058</td>\n",
              "      <td>0.683646</td>\n",
              "      <td>3.568987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_12</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.866240e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.305611</td>\n",
              "      <td>-0.666463</td>\n",
              "      <td>0.025819</td>\n",
              "      <td>0.675121</td>\n",
              "      <td>3.498677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_13</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>9.450218e-17</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.919694</td>\n",
              "      <td>-0.680962</td>\n",
              "      <td>-0.006143</td>\n",
              "      <td>0.661320</td>\n",
              "      <td>3.998092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_14</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.151079e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.818618</td>\n",
              "      <td>-0.664539</td>\n",
              "      <td>0.017676</td>\n",
              "      <td>0.669214</td>\n",
              "      <td>3.913242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_15</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>3.289813e-15</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.524163</td>\n",
              "      <td>-0.665927</td>\n",
              "      <td>0.004529</td>\n",
              "      <td>0.670484</td>\n",
              "      <td>4.338710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_16</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-5.728751e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.241478</td>\n",
              "      <td>-0.684383</td>\n",
              "      <td>-0.018401</td>\n",
              "      <td>0.652103</td>\n",
              "      <td>4.224542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_17</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-1.172396e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-4.710243</td>\n",
              "      <td>-0.629663</td>\n",
              "      <td>0.020866</td>\n",
              "      <td>0.674894</td>\n",
              "      <td>3.584727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_18</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-5.616840e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.576276</td>\n",
              "      <td>-0.666026</td>\n",
              "      <td>0.009615</td>\n",
              "      <td>0.662473</td>\n",
              "      <td>3.890533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_19</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>9.098500e-16</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.771503</td>\n",
              "      <td>-0.676057</td>\n",
              "      <td>0.000224</td>\n",
              "      <td>0.663606</td>\n",
              "      <td>3.690522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature_20</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>-8.810730e-17</td>\n",
              "      <td>1.000050</td>\n",
              "      <td>-3.281709</td>\n",
              "      <td>-0.682515</td>\n",
              "      <td>-0.016295</td>\n",
              "      <td>0.660956</td>\n",
              "      <td>4.115485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>10000.0</td>\n",
              "      <td>1.114000e-01</td>\n",
              "      <td>0.314643</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5af2e84-36e3-4bee-a24b-f7d0429d9f17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5af2e84-36e3-4bee-a24b-f7d0429d9f17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5af2e84-36e3-4bee-a24b-f7d0429d9f17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d5008968-745f-4141-917a-e38a7ef3bb9d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5008968-745f-4141-917a-e38a7ef3bb9d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d5008968-745f-4141-917a-e38a7ef3bb9d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"                                # rango de aproximadamente -4 y 4\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 10000.0,\n        \"max\": 10000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          10000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.024309472972289397,\n        \"min\": -2.8109070626669564e-15,\n        \"max\": 0.1114,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          2.3149482331064063e-15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14956816652466962,\n        \"min\": 0.31464255909525396,\n        \"max\": 1.0000500037503162,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          1.000050003750313\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9608905246496934,\n        \"min\": -4.710243335486705,\n        \"max\": 0.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          -4.649097364078424\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1474774752752683,\n        \"min\": -0.6903079676150133,\n        \"max\": 0.0,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          -0.6333766298614367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01389551014284051,\n        \"min\": -0.01840107384743752,\n        \"max\": 0.03588695134692788,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.03588695134692788\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1463251129537094,\n        \"min\": 0.0,\n        \"max\": 0.6836458820408045,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.6770964110137052\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6779348237661794,\n        \"min\": 1.0,\n        \"max\": 4.338709768047752,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          3.913298754700551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separamos las variables de entrada y la variable objetivo de salida:\n",
        "X = df.drop('target', axis=1).values\n",
        "y = df['target'].values\n",
        "\n",
        "# Dividir el conjunto de datos en entrenamiento (80%) y prueba (20%)\n",
        "# Como vamos a utilizar Validación Cruzada, haremos la partición\n",
        "# en Entrenamiento y Prueba.\n",
        "# Además usamos s\"tratify\" para mantener la proporción de clases en la partición.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17, stratify=y)\n",
        "\n",
        "print(f\"Tamaño del conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
        "print(f\"Tamaño del conjunto de prueba: {X_test.shape[0]} muestras\")"
      ],
      "metadata": {
        "id": "fIhubZHG8a-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f5a38db-b7fc-48b8-e0f6-dcbd7d5c53e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño del conjunto de entrenamiento: 8000 muestras\n",
            "Tamaño del conjunto de prueba: 2000 muestras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hagamos esta partición temporal para tener un valor aproximado del desempeño\n",
        "# mínimo que alcanzará nuestro modelo más simple.\n",
        "Xt, Xv, yt, yv = train_test_split(X_train, y_train, test_size=0.2, random_state=17, stratify=y_train)\n",
        "\n",
        "estrategias = ['most_frequent','prior','stratified','uniform']\n",
        "\n",
        "for estrategia in estrategias:\n",
        "  dummy_clf = DummyClassifier(strategy=estrategia, random_state=17)\n",
        "  dummy_clf.fit(Xt, yt)\n",
        "  y_pred = dummy_clf.predict(Xv)\n",
        "\n",
        "  # Tabla para almacenar resultados\n",
        "  results = []\n",
        "\n",
        "  # \"pos_label\" indica la clase con respecto a la cual evaluar cada métrica.\n",
        "  acc = accuracy_score(yv, y_pred)\n",
        "  rec = recall_score(yv, y_pred, pos_label=1)\n",
        "  prec = precision_score(yv, y_pred, pos_label=1)\n",
        "  f1_sc = f1_score(yv, y_pred, pos_label=1)\n",
        "\n",
        "  results.append({'Accuracy': acc,\n",
        "                'Recall': rec,\n",
        "                'Precision': prec,\n",
        "                'F1 Score': f1_sc\n",
        "                })\n",
        "  print(f\"Estrategia: {estrategia}\")\n",
        "  print(f\"Accuracy: {acc:.4f}\")\n",
        "  print(f\"Recall: {rec:.4f}\")\n",
        "  print(f\"Precision: {prec:.4f}\")\n",
        "  print(f\"F1 Score: {f1_sc:.4f}\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "ItnzozIq8i9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f72aa082-71c9-47cf-99ea-124101b3c098"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrategia: most_frequent\n",
            "Accuracy: 0.8888\n",
            "Recall: 0.0000\n",
            "Precision: 0.0000\n",
            "F1 Score: 0.0000\n",
            "\n",
            "Estrategia: prior\n",
            "Accuracy: 0.8888\n",
            "Recall: 0.0000\n",
            "Precision: 0.0000\n",
            "F1 Score: 0.0000\n",
            "\n",
            "Estrategia: stratified\n",
            "Accuracy: 0.8163\n",
            "Recall: 0.0787\n",
            "Precision: 0.0972\n",
            "F1 Score: 0.0870\n",
            "\n",
            "Estrategia: uniform\n",
            "Accuracy: 0.4825\n",
            "Recall: 0.4494\n",
            "Precision: 0.0988\n",
            "F1 Score: 0.1619\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 1**"
      ],
      "metadata": {
        "id": "_mK6SXmx-m71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **En este ejercicio deseamos obtener el umbral del desempeño mínimo que debiera alcanzar nuestro modelo, es decir, obtener el desempeño del modelo más simple (dummy). Consideraremos las siguientes políticas de la función DummyClassifier(): \"most_frequent\", \"prior, \"stratified\" y \"uniform\".**\n",
        "\n",
        "Recuerda revisar la documentación correspondiente:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html"
      ],
      "metadata": {
        "id": "8Sqh3yly-qu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejercicio 1a**\n",
        "\n",
        "#### **Para los casos \"most_frequent\" y \"prior\" observamos que se obtiene un \"UndefinedMetricWarning\" y nos dice que la métrica Precision no está bien definida (\"ill-defined\") ¿Qué significa este aviso? ¿Y si usamos la fórmula de Precision, qué nos resultaría?**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "El aviso de `UndefinedMetricWarning` significa que el modelo no predijo ninguna instancia para la clase minoritaria (clase 1).\n",
        "\n",
        "Esto indica que el modelo predice que todos los ejemplos pertenecen a la clase mayoritaria (clase 0) y no hay predicciones positivas para la clase minoritaria. Si no hay predicciones positivas TP + FP = 0, la división por cero resulta en un valor indefinido para la precisión.\n",
        "\n",
        "Si usamos la fórmula de Precision, como se mencionó anteriormente, se tendría una forma indefinida de 0/0.\n",
        "\n",
        "Scikit-learn, en estos casos, asigna un valor de 0.0 a la precisión y emite la advertencia para informarnos de esta situación.\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "n-c3u1tIAq5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ejercicio 1b**\n",
        "\n",
        "#### **Supongamos que la métrica que vamos a estar monitoreando es el \"F1-score\". Si esta fuera nuestra decisión y considerando los valores numéricos obtenidos en la celda anterior, ¿cuál de las cuatro políticas (\"most_frequent\", \"prior, \"stratified\", \"uniform\") recomendarías utilizar para obtener el desempeño mínimo que debiera tener nuestro mejor modelo que vamos a construir con RandomForest? Y por lo tanto, ¿cuál sería este valor mínimo? Justifica tu decisión.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Considerando los valores obtenidos:\n",
        "* `most_frequent` -> F1 Score: 0.0000\n",
        "* `prior` -> F1 Score: 0.0000\n",
        "* `stratified` -> F1 Score: 0.0870\n",
        "* `uniform` -> F1 Score: 0.1619\n",
        "\n",
        "Lo mejor será utilizar `uniform` para obtener el desempeño mínimo que deberá tener nuestro mejor modelo con `RandomForest`.\n",
        "\n",
        "El tener un valor de 0.0 en F1 Score, indica un rendimiento pobre, ya sea porque el modelo no predice correctamente la clase positiva o porque tiene un bajo rendimiento en ambas métricas. Es por eso que se descarta `most_frequent` y `prior`.\n",
        "\n",
        "En el caso de `stratified` tiene mejor resultado, sin embargo, a comparación de `uniform`, el valor sigue siendo bajo.\n",
        "\n",
        "El valor mínimo de F1 Score que deberíamos esperar de nuestro modelo de `RandomForest` sería `0.1619`, el valor obtenido con la estrategia `uniform`.\n",
        "\n",
        "Cualquier modelo de `RandomForest` que construyamos debería superar este rendimiento para considerarse útil, especialmente en la detección de la clase minoritaria.\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "oNyEqgq3Ph4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 2:**"
      ],
      "metadata": {
        "id": "Ee9SfRM5UXAa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* #### **En lo que resta de esta primera parte de la Actividad, supondremos que la métrica F1-score es la que nos interesa monitorear.**\n",
        "\n",
        "* #### **Así, a continuación deberás encontrar la mejor configuración del modelo Bosque Aleatorio que te resulte en la mejor métrica F1-score con respecto a la clase positiva 1.**\n",
        "\n",
        "* #### **Además, el modelo no debe estar sub-entrenado o sobre-entrenado con respecto a esta métrica F1-score.**\n",
        "\n",
        "* #### **Deberas decidir si se requiere incluir alguna técnica de sub-mestreo y/o sobre-muestro.**\n",
        "\n",
        "* #### **Incluye los hiperparámetros que consideres adecuados, pero recuerda que si incluyes demasiados, el tiempo de entrenamiento se incrementa.**\n",
        "\n",
        "\n",
        "Revisa la documentación correspondiente:\n",
        "\n",
        "* https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "* https://imbalanced-learn.org/stable/references/over_sampling.html\n",
        "\n",
        "* https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
      ],
      "metadata": {
        "id": "EdMskCNxaew7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejercicio 2:\n",
        "\n",
        "\n",
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# +++++++ INICIA SECCIÓN PARA INCLUIR TUS AJUSTES ++++++++++++++++++\n",
        "\n",
        "# Incluyo algunos ejemplos, pero puedes incluir más si lo deseas, revisa\n",
        "# la documentación correspondiente.\n",
        "\n",
        "# Definimos nuestro pipeline:\n",
        "pipeline = Pipeline([\n",
        "    #('smote', SMOTE()),  # Descomenta si deseas usar técnica de balanceo\n",
        "    ('model', RandomForestClassifier(random_state=17))\n",
        "])\n",
        "\n",
        "# Definimos los posibles valores para la búsqueda de malla.\n",
        "# El total de opciones a buscar en esta malla se obtiene con el producto\n",
        "# de la cantidad de casos de cada hiperparámetro.\n",
        "# Observa la diferencia entre el guión bajo doble y el sencillo.\n",
        "param_grid = {\n",
        "    'smote__k_neighbors': [5,7],  # Descomenta para usar hiperparámetros de la técnica de balanceo.\n",
        "    'model__n_estimators': [50,100],  # Hiperparámetros del modelo ...\n",
        "    #'model__max_depth': [],\n",
        "    #'model__min_samples_split': [],\n",
        "    #'model__class_weight':[]\n",
        "\n",
        "    # agregar todos los demás hiperparámetros que desees...\n",
        "}\n",
        "\n",
        "\n",
        "# Utilizaremos Validación Cruzada Estratificada:\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)\n",
        "\n",
        "# Aquí definimos la métrica a utilizar, en nuestro caso, F1-score:\n",
        "scorer = make_scorer(f1_score, average='binary', pos_label=1) # Esta línea no la modifiques.\n",
        "\n",
        "# Conjuntamos todo en la búsqueda de malla GridSearch:\n",
        "grid_search = RandomizedSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=None,   # Aquí indicas el número de opciones del param_grid en los que harás la búsqueda.\n",
        "    cv=cv,\n",
        "    scoring=scorer,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# +++++++++++++ TERMINA SECCIÓN PARA REALIZAR AJUSTES +++++++++++++++\n",
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "# Hacemos el ajuste del modelo con los datos de entrenamiento:\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Y evaluamos con el mejor  conjunto de prueba\n",
        "#best_model = grid_search.best_estimator_\n",
        "#y_pred = best_model.predict(X_test)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(f\"\\nMejores parámetros encontrados:\\n {best_params}\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# **************************************************************************\n",
        "# Gráfico de curvas de aprendizaje del mejor modelo.\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Definimos tamaños de entrenamiento relativos al conjunto de entrenamiento:\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calculamos curvas de aprendizaje con cross-validation:\n",
        "train_sizes, train_scores, valid_scores = learning_curve(\n",
        "    estimator=best_model,     # Usamos el mejor modelo encontrado\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    train_sizes=train_sizes,  # Tamaños de entrenamiento a evaluar\n",
        "    cv=5,\n",
        "    scoring='f1',             # Métrica a evaluar, en nuetro caso F1-score\n",
        "    n_jobs=-1,                # Usar todos los núcleos disponibles\n",
        "    random_state=17\n",
        ")\n",
        "\n",
        "# Calculamos medias y desviaciones estándar:\n",
        "train_mean = np.mean(train_scores, axis=1)\n",
        "train_std = np.std(train_scores, axis=1)\n",
        "valid_mean = np.mean(valid_scores, axis=1)\n",
        "valid_std = np.std(valid_scores, axis=1)\n",
        "\n",
        "\n",
        "# Área sombreada en el gráfico para la desviación estándar:\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.fill_between(train_sizes, train_mean - train_std,\n",
        "                 train_mean + train_std, alpha=0.1, color='blue')\n",
        "plt.fill_between(train_sizes, valid_mean - valid_std,\n",
        "                 valid_mean + valid_std, alpha=0.1, color='orange')\n",
        "\n",
        "# Grafcamos el polígono de las medias:\n",
        "plt.plot(train_sizes, train_mean, 'o-', color='blue', label='F1-score de Entrenamiento')\n",
        "plt.plot(train_sizes, valid_mean, 'o-', color='orange', label='F1-score de Validación (Cruzada)')\n",
        "\n",
        "\n",
        "plt.title(f'Curvas de Aprendizaje del mejor modelo')\n",
        "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
        "plt.ylabel('métrica F1-score')\n",
        "plt.grid(True)\n",
        "plt.legend(loc='lower right')\n",
        "#plt.ylim([0.8, 1.01])  # Puedes ajustar el rango del eje Y según tus datos\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hNv4Vz9EGx_R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7e772898-c036-47ad-ca16-a22542b98a5d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidParameterError",
          "evalue": "The 'n_iter' parameter of RandomizedSearchCV must be an int in the range [1, inf). Got None instead.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-db1510cc03fa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# Hacemos el ajuste del modelo con los datos de entrenamiento:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Y evaluamos con el mejor  conjunto de prueba\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpartial_fit_and_fitted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m                 \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m             with config_context(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0maccepted\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \"\"\"\n\u001b[0;32m--> 436\u001b[0;31m         validate_parameter_constraints(\n\u001b[0m\u001b[1;32m    437\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameter_constraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 )\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise InvalidParameterError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"The {param_name!r} parameter of {caller_name} must be\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\" {constraints_str}. Got {param_val!r} instead.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidParameterError\u001b[0m: The 'n_iter' parameter of RandomizedSearchCV must be an int in the range [1, inf). Got None instead."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search   # mejor configuración obtenida"
      ],
      "metadata": {
        "id": "d_0xMYipqpiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Conjunto de Prueba**"
      ],
      "metadata": {
        "id": "f4GHJuyHuhYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pasemos a predecir con el conjunto de Prueba (Test) una vez\n",
        "# que encontraste tu mejor modelo.\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Probabilidades de predicción para la clase 1\n",
        "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Matriz de confusión:\n",
        "cm = confusion_matrix(y_test, y_pred, normalize='true')\n",
        "plt.figure(figsize=(3,3))\n",
        "sns.heatmap(cm, annot=True, fmt='.2g', cmap='Blues', cbar=False)   # en caso de enteros: fmt='d'\n",
        "plt.title('Matriz de Confusión')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.xticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.yticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lhLYVImfClOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reporte de clasificación estándar\n",
        "print(\"Reporte de Clasificación Estándar:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "WmYt6w-yCoPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Nuevo umbral de decisión con F1-score**"
      ],
      "metadata": {
        "id": "L6CuWELf7yYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En problemas desbalanceados, el umbral por defecto de 0.5 puede no ser el óptimo\n",
        "# para hacer las predicciones:\n",
        "# Si y_proba>0.5, entonces lo asignamos a la Clase_1, en otro caso, a la Clase_0.\n",
        "\n",
        "# Vamos a encontrar el umbral que maximiza el F1-score y determinar si sigue\n",
        "# siendo el valor por defecto.\n",
        "\n",
        "thresholds = np.arange(0.1, 0.9, 0.05)\n",
        "f1_scores = []\n",
        "\n",
        "for threshold in thresholds:\n",
        "    y_binary = (y_proba >= threshold).astype(int)\n",
        "    f1 = f1_score(y_test, y_binary)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "# Encontrar el mejor umbral\n",
        "best_threshold_idx = np.argmax(f1_scores)\n",
        "best_threshold = thresholds[best_threshold_idx]\n",
        "best_f1 = f1_scores[best_threshold_idx]\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(thresholds, f1_scores, 'o-', color='purple')\n",
        "plt.axvline(x=best_threshold, color='r', linestyle='--',\n",
        "            label=f'Umbral óptimo = {best_threshold:.2f}, F1 = {best_f1:.3f}')\n",
        "plt.axvline(x=0.5, color='g', linestyle='--',\n",
        "            label=f'Umbral predeterminado = 0.5, F1 = {f1_score(y_test, (y_proba >= 0.5).astype(int)):.3f}')\n",
        "plt.title('F1-score vs Umbral de Decisión')\n",
        "plt.xlabel('Umbral')\n",
        "plt.ylabel('F1-score')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "shABDCkaC98a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluar el modelo con el umbral óptimo\n",
        "y_pred_optimal = (y_proba >= best_threshold).astype(int)\n",
        "print(\"\\nResultados con umbral óptimo:\")\n",
        "print(classification_report(y_test, y_pred_optimal))"
      ],
      "metadata": {
        "id": "lgEmaWsRDBMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión con umbral óptimo\n",
        "cm_optimal = confusion_matrix(y_test, y_pred_optimal, normalize='true')\n",
        "plt.figure(figsize=(3,3))\n",
        "sns.heatmap(cm_optimal, annot=True, fmt='.2g', cmap='Blues', cbar=False)\n",
        "plt.title(f'Matriz de Confusión (Umbral = {best_threshold:.2f})')\n",
        "plt.xlabel('Predicción')\n",
        "plt.ylabel('Real')\n",
        "plt.xticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.yticks([0.5, 1.5], ['Clase 0', 'Clase 1'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H4Q86k_ODDJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 3**"
      ],
      "metadata": {
        "id": "npsG0Br_756s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Con base a los resultados obtenidos responde los siguientes incisos que ayuden a concluir esta primera parte de la actividad.**\n",
        "\n",
        "* **Ejercicio 3a: Comenta por qué el modelo final que obtuviste no está subentrenado, ni sobreentrenado.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "* **Ejercicio 3b: Comenta las diferencias (si las hay) que observas entre usar el umbral predeterminado 0.5 y el nuevo umbral.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "* **Ejercicio 3c: Comenta el impacto que viste al usar o no alguna técnica de submuestreo.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "* **Ejercicio 3d: incluye tus comentarios finales de esta primera parte de la actividad.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n"
      ],
      "metadata": {
        "id": "XEMqYuHV7-AU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PARTE - 2 - XGBoost - Regressor**"
      ],
      "metadata": {
        "id": "CLWCrmnpse89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ver documentación para hiperparámetros del modelo:\n",
        "\n",
        "https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.XGBRegressor\n",
        "\n",
        "https://xgboost.readthedocs.io/en/stable/parameter.html"
      ],
      "metadata": {
        "id": "dPL4pQExqaYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_validate\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import learning_curve\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Semilla para reproducibilidad\n",
        "np.random.seed(17)"
      ],
      "metadata": {
        "id": "UXBwNYWAsuSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generamos un dataset de regresión con 10,000 muestras y 20 características\n",
        "X, y = make_regression(n_samples=10_000,\n",
        "                       n_features=20,\n",
        "                       n_informative=15,\n",
        "                       n_targets=1,\n",
        "                       noise=100.,\n",
        "                       random_state=17)\n",
        "\n",
        "# Convertimos a DataFrame de Pandas:\n",
        "df = pd.DataFrame(X, columns=[f\"feat_{i}\" for i in range(X.shape[1])])\n",
        "df['target'] = y\n",
        "\n",
        "print(\"Forma del dataset:\", df.shape)\n"
      ],
      "metadata": {
        "id": "Cb_-4O02sxxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().T   # Observa que estos factores ya están en un rango análogo de -4 a 4, aprox."
      ],
      "metadata": {
        "id": "pmzbKdYJ-ThU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# División en Train vs Test (80% vs 20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=17)\n",
        "\n",
        "print(\"Tamaño de entrenamiento:\", X_train.shape)\n",
        "print(\"Tamaño de test:\", X_test.shape)"
      ],
      "metadata": {
        "id": "mawdVgZEs14t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 4**"
      ],
      "metadata": {
        "id": "mSgbKTzTDh65"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Desempeño del modelo base (baseline)**\n",
        "\n",
        "#### **Las líneas de código de la siguiente celda son un análisis que nos ayudarán posteriormente a determinar si el modelo que obtengamos estará o no subentrenado.**\n",
        "\n",
        "* **Ejercicio 4a: Explica con tus palabras de manera clara lo que hacen estas líneas de código para poder obtener de ahí el modelo base (baseline) de un modelo de regresión.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "* **Ejercicio 4b: Explica el significado de los valores numéricos mostrados: Valor_1 y Valor_2.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "IZIFFGh9_IBv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xt, Xv, yt, yv = train_test_split(X_train, y_train, test_size=0.2, random_state=17)\n",
        "yt_mean = np.mean(yt)\n",
        "y_pred_baseline = np.full(shape=yv.shape, fill_value=yt_mean)\n",
        "rmse_baseline = np.sqrt(mean_squared_error(yv, y_pred_baseline))\n",
        "\n",
        "print(f\"Valor_1-Ejercicio-4b: {yt_mean:.4f}\\n\")\n",
        "print(f\"Valor_2-Ejercicio-4b: {rmse_baseline:.4f}\")"
      ],
      "metadata": {
        "id": "lOJRJ4ASwl42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 5**"
      ],
      "metadata": {
        "id": "xTNI0fB5GzsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* #### **Encuentra la mejor configuración del modelo XGBoost que te resulte con la métrica RMSE.**\n",
        "\n",
        "* #### **Además, el modelo no debe estar sub-entrenado o sobre-entrenado.**\n",
        "\n",
        "* #### **Incluye los hiperparámetros que consideres adecuados, pero recuerda que si incluyes demasiados, el tiempo de entrenamiento se incrementa.**"
      ],
      "metadata": {
        "id": "RjrLzN-KG3w2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "# +++++++ INICIA SECCIÓN PARA INCLUIR TUS AJUSTES ++++++++++++++++++\n",
        "\n",
        "# Instanciamos el modelo base:\n",
        "model = XGBRegressor(random_state=17, n_jobs=-1)\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    # Incluye aquí todos los casos que desees buscar en la malla.\n",
        "}\n",
        "\n",
        "# Métricas de regresión a evaluar:\n",
        "scoring = {\n",
        "    'MAE': 'neg_mean_absolute_error',\n",
        "    'RMSE': 'neg_root_mean_squared_error',\n",
        "    'R2': 'r2',\n",
        "    'MAPE': 'neg_mean_absolute_percentage_error'\n",
        "}\n",
        "\n",
        "\n",
        "# Configuración del grid search aleatorio:\n",
        "grid_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_grid,\n",
        "    n_iter=None,         # Indica la cantidad de casos a buscar en la malla.\n",
        "    scoring=scoring,\n",
        "    refit='RMSE',      # Selecciona el mejor modelo según esta métrica RMSE.\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# +++++++++++++ TERMINA SECCIÓN PARA REALIZAR AJUSTES +++++++++++++++\n",
        "# +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "# Pasamos al entrenamiento del modelo:\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# **********************************************************************\n",
        "# Medimos el desempeño del modelo con respecto al modelo base (baseline):\n",
        "rmse_xgb = -grid_search.best_score_\n",
        "\n",
        "print(f\"\\nRMSE del modelo XGBoost: {rmse_xgb:.4f}\\n\")\n",
        "print(f\"Resultado-para-el-Ejercicio-6b: {(rmse_baseline - rmse_xgb) / rmse_baseline * 100:.1f}%\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# ***********************************************************************\n",
        "# Visualizamos el aprendizaje del mejor modelo:\n",
        "# Usamos el mejor modelo encontrado por GridSearchCV\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Definimos los tamaños de entrenamiento a evaluar\n",
        "train_sizes = np.linspace(0.1, 1.0, 10)\n",
        "\n",
        "# Calcular las curvas de aprendizaje usando RMSE\n",
        "train_sizes, train_scores, test_scores = learning_curve(\n",
        "    estimator=best_model,\n",
        "    X=X_train,\n",
        "    y=y_train,\n",
        "    train_sizes=train_sizes,\n",
        "    cv=5,\n",
        "    scoring='neg_root_mean_squared_error',\n",
        "    n_jobs=-1,\n",
        "    shuffle=True,\n",
        "    random_state=17\n",
        ")\n",
        "\n",
        "# Convertimos los puntajes negativos de RMSE a positivos\n",
        "train_rmse = -train_scores.mean(axis=1)\n",
        "test_rmse = -test_scores.mean(axis=1)\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(train_sizes, train_rmse, label='Entrenamiento (RMSE)', color='blue')\n",
        "plt.plot(train_sizes, test_rmse, label='Validación (RMSE)', color='red', linestyle='--')\n",
        "plt.title('Curva de Aprendizaje - RMSE')\n",
        "plt.xlabel('Tamaño del conjunto de entrenamiento')\n",
        "plt.ylabel('RMSE')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q5bgO_FJs81Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Obtenemos finalmente información con respecto al conjunto de Prueba:**"
      ],
      "metadata": {
        "id": "6vlVlTOCZ6KP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search   # configuración del mejor modelo encontrado"
      ],
      "metadata": {
        "id": "Na4u4JwEWW3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones en el conjunto de Prueba (Test) con el mejor modelo encontrado:\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "# Calculamos los valores de las métricas:\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "\n",
        "print(\"\\nResultados-para-el-Ejercicio-6c:\")\n",
        "print(\"\\nMétricas en Test:\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R²: {r2:.4f}\")\n",
        "print(f\"MAPE: {mape:.2f}%\")"
      ],
      "metadata": {
        "id": "gltpxoh_vACA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de dispersión entre valores reales y predichos\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel('Valores reales')\n",
        "plt.ylabel('Predicciones')\n",
        "plt.title('Valores reales vs Predicciones')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WvmBeW72v6F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 6**"
      ],
      "metadata": {
        "id": "ZOAL8pHKbVNr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Con base a los resultados obtenidos responde los siguientes incisos que ayuden a concluir esta segunda parte de la actividad.**\n",
        "\n",
        "* **Ejercicio 6a: Comenta por qué el modelo final que obtuviste no está subentrenado, ni sobreentrenado.**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "* **Ejercicio 6b: Indica cómo interpretas el valor obtenido en \"Resultado-para-el-Ejercicio-6b\".**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "\n",
        "\n",
        "* **Ejercicio 6c: Indica cómo interpretas cada uno de los resultados que obtuviste en \"Resultados-para-el-Ejercicio-6c\".**\n",
        "\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "* **Ejercicio 3d: Incluye tus comentarios finales de esta segunda parte de la actividad.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "W6mKKg8AbQn3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Ejercicio - 7**"
      ],
      "metadata": {
        "id": "UrxY-00hdqOQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Ejercicio 7: incluye tus comentarios finales de esta actividad.**\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "Incluye aquí tus comentarios.\n",
        "\n",
        "None\n",
        "\n",
        "++++++++++++++++++++++++++++++++++++++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "HfBtXn6GdxYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fin de la Actividad de modelos basados en áboles**"
      ],
      "metadata": {
        "id": "phuZNBsjeDQh"
      }
    }
  ]
}